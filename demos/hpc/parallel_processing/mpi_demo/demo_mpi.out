> # Cluster computing with "parallel" and "BiocParallel" packages.
> #
> # Example developed from "Simulation for Data Science with R" (Templ, 2016). 
> # Book (Packt): https://bit.ly/2LsAHov Ch2 code (Github): https://bit.ly/3dLh3jJ
> #
> # Aside from packages loaded with "library", you will also need to install:
> # - MASS
> # - rlecuyer
> # - Rmpi
> # - robustbase
> 
> # Load packages
> library(parallel)
> library(BiocParallel)
> 
> # --------------
> # Configuration
> # --------------
> 
> # Setup defaults
> default_cl_type <- "SOCK"
> default_workers <- 10000
> default_R <- 0
> 
> # Setup random number generator (RNG)
> RNGkind("L'Ecuyer-CMRG")
> seed <- 123
> 
> # Choose to skip serial boot or not
> skip_serial_boot <- TRUE
> 
> # Initialize variables
> cl_type <- ""
> workers <- 0
> R <- 0
> 
> # Assign variables from command-line arguments if present and valid
> args <- (commandArgs(TRUE))
> if (length(args) == 0) {
+   print("No command-line arguments supplied.")
+ } else {
+   for (i in 1:length(args)) {
+     eval(parse(text = args[[i]]))
+   }
+ }
> 
> # If "cl_type" is not valid, use default
> if (!(cl_type %in% c("SOCK", "MPI"))) cl_type <- default_cl_type
> 
> # If the number of workers (slaves) is not valid, use default
> workers <- as.integer(workers)
> if (workers <= 0) workers <- default_workers
> 
> # If the number of bootstraps is not valid, use default
> R <- as.integer(R)
> if (R <= 0) R <- default_R
> 
> results_filename <- 
+   paste("rob_cov_test", R, workers, cl_type, ".csv", sep = "_")
> 
> # -----------------
> # Define Functions
> # -----------------
> 
> # Calculate robust covariance foreach bootstrap using a single core
> f <- function(X.seq, ...) {
+   # suppressPackageStartupMessages(require(robustbase))
+   
+   data(Cars93, package = "MASS")
+   n <- nrow(Cars93)
+   
+   sapply(X.seq, function(x) {
+     robustbase::covMcd(Cars93[sample(1:n, replace=TRUE),
+                               c("Price", "Horsepower")], cor = TRUE)$cor[1,2]
+   })
+ }
> 
> # Summarize results
> quant.fun <- function(x, alpha = 0.05) {
+   quantile(x, probs = c(alpha / 2, 1 - alpha / 2))
+ }
> 
> # Create empty results data frame
> create_results_df <- function() {
+   data.frame(
+     R = as.numeric(NULL),
+     cl_type = as.character(NULL),
+     package = as.character(NULL),
+     fun = as.character(NULL),
+     elapsed = as.numeric(NULL),
+     `2.5%` = as.numeric(NULL),
+     `97.5%` = as.numeric(NULL),
+     check.names = FALSE,
+     stringsAsFactors = FALSE
+   )
+ }
> 
> # Combine results into a data frame
> combine_results <- function(cl_type, package, fun, elapsed, ci, dec = 5) {
+   data.frame(R = R, workers = workers, cl_type = cl_type, 
+              package = package, fun = fun, elapsed = round(elapsed, dec), 
+              t(round(ci, dec)), stringsAsFactors = FALSE, check.names = FALSE)
+ }
> 
> # ------------------
> # Serial Processing
> # ------------------
> 
> # Get data
> data(Cars93, package = "MASS")
> n <- nrow(Cars93)
> 
> # Calculate robust covariance
> robustbase::covMcd(Cars93[, c("Price", "Horsepower")], cor = TRUE)$cor[1,2]
[1] 0.8447125
> 
> if (skip_serial_boot == FALSE) {
+   # Perform robust covariance calculation with serial computing
+   set.seed(seed)
+   st <- system.time(ci <- f(X.seq = 1:R))
+   res <- quant.fun(ci)
+   
+   # Combine results
+   results <- combine_results(cl_type = 'none', 
+                              package = 'none', fun = 'none', 
+                              elapsed = st[['elapsed']], ci = res)
+ } else {
+   results <- create_results_df()
+ }
> 
> # ------------------------------------
> # Parallel Processing with "parallel"
> # ------------------------------------
> 
> # Make a cluster of "slave nodes" with a type of either "SOCK" or "MPI".
> # As a maximum, use one less than the total number of cores (or workers).
> 
> cl <- makeCluster(spec = workers, type = cl_type)
Loading required namespace: Rmpi
	2 slaves are spawned successfully. 0 failed.
> cl
[[1]]
$rank
[1] 1

$RECVTAG
[1] 33

$SENDTAG
[1] 22

$comm
[1] 1

attr(,"class")
[1] "MPInode"

[[2]]
$rank
[1] 2

$RECVTAG
[1] 33

$SENDTAG
[1] 22

$comm
[1] 1

attr(,"class")
[1] "MPInode"

attr(,"class")
[1] "spawnedMPIcluster" "MPIcluster"        "cluster"          
> 
> # Make the data, function and package "robustbase" available for all workers
> #res <- clusterEvalQ(cl, library("robustbase"))
> #res <- clusterEvalQ(cl, data(Cars93, package = "MASS"))
> #res <- clusterExport(cl, "n")
> 
> # Set a random seed for all workers
> res <- clusterSetRNGStream(cl, iseed = seed)
> 
> # Split bootstrap sequence (1:R) into a list of n = workers vectors
> X.split <- clusterSplit(cl, 1:R)
> 
> # Perform calculation with parallel computing using "parallel::clusterApply()"
> st <- system.time(ci_boot <- clusterApply(cl, x = X.split, fun = f))
> res <- quant.fun(unlist(ci_boot))
> 
> # Stop the cluster
> stopCluster(cl)
[1] 1
> 
> # Combine results
> results <- rbind(results, 
+                  combine_results(cl_type = cl_type, 
+                                  package = 'parallel', fun = 'clusterApply', 
+                                  elapsed = st[['elapsed']], ci = res))
> 
> # If running with "SOCK", compare with "FORK" using "parallel::mclapply()"
> if (cl_type == "SOCK" && Sys.info()[['sysname']] != "Windows") {
+   set.seed(seed)
+   st <- system.time(ci_boot <- mclapply(X.split, f, mc.cores = workers))
+   res <- quant.fun(unlist(ci_boot))
+   
+   # Combine results
+   results <- rbind(results, 
+                    combine_results(cl_type = 'FORK', 
+                                    package = 'parallel', fun = 'mclapply', 
+                                    elapsed = st[['elapsed']], ci = res))
+ }
> 
> # ----------------------------------------
> # Parallel Processing with "BiocParallel"
> # ----------------------------------------
> 
> # "BiocParallel" is like "parallel" in that it implements the functionality
> # of earlier "snow" and "multicore" packages, but with a simpler method of
> # switching between computation backends using a more consistent interface.
> 
> # Split bootstrap sequence (1:R) into a list of n = workers vectors
> # Similar to: X.split <- clusterSplit(cl, 1:R)
> X.split <- split(1:R, rep_len(1:workers, length(1:R)))
> 
> # Perform calculation with parallel computing using "BiocParallel::bplapply()"
> param <- SnowParam(workers = workers, type = cl_type, RNGseed = seed)
> st <- system.time(ci_boot <- bplapply(X = X.split, FUN = f, BPPARAM = param))
	2 slaves are spawned successfully. 0 failed.
> res <- quant.fun(unlist(ci_boot))
> 
> # Combine results
> results <- rbind(results, 
+                  combine_results(cl_type = cl_type, 
+                                  package = 'BiocParallel', fun = 'bplapply', 
+                                  elapsed = st[['elapsed']], ci = res))
> 
> # If running with "SOCK", compare with "FORK", the default for "MulticoreParam"
> if (cl_type == "SOCK" && Sys.info()[['sysname']] != "Windows") {
+   param <- MulticoreParam(workers = workers, RNGseed = seed)
+   st <- system.time(ci_boot <- bplapply(X = X.split, FUN = f, BPPARAM = param))
+   res <- quant.fun(unlist(ci_boot))
+ 
+   # Combine results
+   results <- rbind(results, 
+                    combine_results(cl_type = 'FORK', 
+                                    package = 'BiocParallel', fun = 'bplapply', 
+                                    elapsed = st[['elapsed']], ci = res))
+ }
> 
> # Save test results
> write.csv(results, results_filename, row.names = FALSE)
> 
> proc.time()
   user  system elapsed 
585.064  98.115 683.265 
