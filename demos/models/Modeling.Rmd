---
title: "Modeling - Part 1"
subtitle: "DEOHS Coders Group"
author: "Nancy Carmona, Chris Zuidema and Brian High"
date: "4/9/2021"
output:
  html_document:
    keep_md: true
editor_options: 
  chunk_output_type: inline
---

# Setup

Rmarkdown setup, directory organization, and data download.

```{r setup, include=FALSE}
#-----setup options-----

# Set knitr options
knitr::opts_chunk$set(
  echo = TRUE,
  cache = FALSE,
  cache.comments = FALSE,
  message = FALSE,
  warning = FALSE
)

# Clear workspace of all objects and unload all extra (non-base) packages
rm(list = ls(all = TRUE))

if (!is.null(sessionInfo()$otherPkgs)) {
  res <- suppressWarnings(map(
    paste('package:', names(sessionInfo()$otherPkgs), sep = ""),
    detach,
    character.only = TRUE,
    unload = TRUE,
    force = TRUE
  ))
  
}
```

```{r load.libraries.pacman, echo=FALSE, include=FALSE, eval=TRUE}
#-----load libraries pacman-----

# load pacman, installing if needed
if (!require("pacman")) {install.packages("pacman")}

# load other packages, installing as needed
pacman::p_load(knitr, dplyr, tidyr, modelr, stringr, ggplot2, purrr, readr,
               broom, lubridate, stats, titanic)

```

# Goal

The goal of this exercise is to learn how to efficiently run many models and
extract results in a tidy manner.
 
# Acknowledgements 

Broom, https://broom.tidymodels.org/

Modeling tutorial, https://r4ds.had.co.nz/model-basics.html#model-basics 

 
# What is modeling? 

Models are a tool for extracting patterns out of data.  

In R, the `lm()`, or “linear model,” function can be used to create a simple
regression model. Ideally, the model will capture true “signals” (i.e. patterns
generated by the phenomenon of interest), and ignore “noise” (i.e. random
variation that you’re not interested in).

# Load and prepare data

```{r load.data}
 
#load data from "titanic" package 
titanic <- as.data.frame(titanic_train) 

# Prepare dataset 
titanic <- titanic_train %>% drop_na()

# view names in the dataset 
names(titanic)

# view structure of dataset
glimpse(titanic)


```

# Typical regression modeling workflow

After preparing data, typical regression modeling steps might be:

  * fit a model (e.g. with `lm()`)
  * call `summary()` on the model fit object
  * extract values and parameters of interest by accessing pieces of the summary
    (e.g. with the `$` operator) 
  * build a table with extracted vales by one or a combination of the following:
    - assigning extracted pieces to objects 
    - extracting pieces within a dataframe or table call 
    - copying and pasting output into another program (e.g. MS word or excel)

```{r lm.model}

# fit model and assign for use in later calculations and analyses 
mod1 <- lm(Survived ~ Age, data = titanic)

# save model summary  
mod1_summary <- summary(mod1) 

# print summary 
mod1_summary

# examine what elements are in the `summary.lm` object
names(mod1_summary)

# options to access coefficients 
coefficients(mod1_summary)
mod1_summary$coefficients

# access R2
mod1_summary$r.squared


```

As you can see in the previous chunk, the `summary()` function provides us with
information, including t-test, F-test, R-squared, residuals, and significance
values. However, these values are not saved in a manner that we can easily use
the results as data. You can access data with the `$` operator like the example
above, and also copy and paste results out of the console, but if you had many
models you wanted to explore, this could quickly become time-consuming and
tedious. 

Constructing a summary table, such as the one below also becomes
daunting when the number of models gets larger. The example below isn't awful in
terms of best practices, but it is going to be impractical when the number of
models grows.

```{r manual.summary.table}

# new models
mod2_summary <- summary(lm(Survived ~ Age + Sex, data = titanic))
mod3_summary <- summary(lm(Survived ~ Age + Sex + Pclass, data = titanic))
mod4_summary <- summary(lm(Survived ~ Age + Sex + Fare, data = titanic))

# you could construct a list, something like this to store the model results
coeffs <- list(
  mod1 = as_data_frame(mod1_summary$coefficients, rownames = "coefficient"),
  mod2 = as_data_frame(mod2_summary$coefficients, rownames = "coefficient"),
  mod3 = as_data_frame(mod3_summary$coefficients, rownames = "coefficient"),
  mod4 = as_data_frame(mod4_summary$coefficients, rownames = "coefficient")
) %>% 
  
  # then the models together 
  bind_rows(.id = "model") %>% 
  
  # round if needed...
  mutate_if(is.double, round, 3)

# show summary
coeffs

```


# Extracting model fit using `broom` 

In the previous sections we saw that model results are stored in an object,
internally this is a list of values. The package `broom` has functions to help
summarize key information about models in tidy tibbles.

  * `tidy()` summarizes information about model components
  * `glance()` reports information about the entire model

Using `tidy()` on a model object produces a `tibble` where each row contains
information about an important component of the model. For regression models,
this corresponds to regression coefficients. This is can be useful if you want
to inspect a model or create custom visualizations.

We'll use the `tidy()` and `glance()` functions from the `broom` packages in
the next section, so let's first take a look at what they do, how they'll fit into
the many models framework, and how they can help us more easily summarize many
models. We use `kable` from the `knitr` package to create a table. 

* Note *

When using mixed models, i.e. running many models with `lme4::lmer()`, we
extract estimates using `broom.mixed::tidy()`.

```{r preview.tidy.glance}

# tidy produces a dataframe of the model coefficients, which can be piped right
# into a table
tidy(mod1) %>% kable(digits = 3)

# glance provides a dataframe of the performace measures
glance(mod1)

```


# Programmatically specify regression models

While our 4 models isn't so difficult to handle, we hope to demonstrate some
useful techniques for times when there are many more models to run.

## Brute force method
 
Next, let's specify the formulas, run the regressions and organize the output
with `broom` functions programmatically. Once the parameters of interest are in
a dataframe, they can be manipulated easily with familiar `dplyr` functions.

We use `map()` from `purrr` to apply `glance()` and `tidy()` to many models. 

```{r programmatically.simple.example}

# define formulas using `modelr::formulas()`
lm_formulas <- formulas(~Survived, 
                        mod1 = ~ Age, 
                        mod2 = ~ Age + Sex, 
                        mod3 = ~ Age + Sex + Pclass,
                        mod4 = ~ Age + Sex + Fare)

# fit models
mdls <- map(lm_formulas, lm, data = titanic)

# extract overall model parameters and coefficient summaries into lists
coeff_summ <- map(mdls, tidy, conf.int = TRUE)
model_summ <- map(mdls, glance)

# create overall model summary table
model_summ_tbl <- model_summ %>% 
  bind_rows(.id = "model") %>% 
  mutate(formula = as.character(lm_formulas)) %>% 
  select(model, formula, r.squared, p.value, AIC) %>% 
  mutate_if(is.double, round, 3)

# show tables
model_summ_tbl

```

## Nested approach

Often we are faced with a dataset we'd like to run stratified models on. The
nesting workflow makes that pretty easy.

Using `fit_with()` with `map()` creates a double-nested list structure for the 
model fit objects, so we use `map()` nested with `map()` to apply `glance()` and 
`tidy()` to them.

```{r programatically.nested.more.complicated.example}

# define formulas again 
# (this is unnecessary to repeat, but just here so this chunk is self-contained)
lm_formulas <- formulas(~Survived, 
                        mod1 = ~ Age, 
                        mod2 = ~ Age + Sex, 
                        mod3 = ~ Age + Sex + Pclass,
                        mod4 = ~ Age + Sex + Fare)

# run nested data pipeline
df_nested <- titanic %>% 
  
  # remove missing values (not marked `NA`)
  filter (Embarked != "") %>% 
  
  # group by variable of interest, then nest
  group_by(Embarked) %>% 
  nest() %>% 
  
  # use `mutate()` to fit models and extract parameters of interest
  mutate(
    
    # using `map` fit the linear models
    # `map` is from the purrr package
    model = map(.x = data, .f = ~fit_with(lm, lm_formulas, data = .x)),
    
    # extract model summaries with `glance()`
    model_summ = map(model, map, glance),
    
    # extract model coefficient estimates with `tidy()`
    coeff_summ = map(model, map, tidy)
    ) 

# at this point we still have a nested dataframe, let's take a look
df_nested

```

From here we have to `unnest()` the nested columns. Since the results were 
double-nested, we use `unnest()` twice to flatten the data structure.

```{r extract.nested}

# lets make a function to extract objects/columns of interest in the nested
# dataframe and rearrange with dplyr
extract_nested <- function(nested, variable, frmls){
  
  # define variable for use in non-standard evaluation in pipeline
  var <- enquo(variable)
  
  # start with nested dataframe
  nested %>%
    
    # select columns of interest (note use of `!!` indicating `var` should be evaluated)
    select(Embarked, !!var) %>% 
    
    # unnest 
    unnest(!!var) %>% 
    
    # add model formulas to dataframe
    mutate(formula = as.character(frmls)) %>% 
    
    # unnest
    unnest(!!var) %>% 
    
    # put formulas all the way to the left 
    relocate(formula) %>% 
    
    # round 
    mutate_if(is.double, round, 3)
  
}


# use function for coefficient summary 
extract_nested(nested = df_nested, variable = coeff_summ, frmls = lm_formulas)

# let's assign the the model summary to an object
df_model_summ <- extract_nested(nested = df_nested, 
                                variable = model_summ, 
                                frmls = lm_formulas)

# show model summary
df_model_summ

```


# Plotting models in `ggplot`

We can visualize patterns in the data with `ggplot()` by plotting the
relationship between variables with `stat_smooth(formula = , family = )`.

```{r lm.plot1}
# simple lm plot
# Create plot.
ggplot(titanic, aes(x = Age, y = Survived)) + geom_point() + 
  stat_smooth(formula = "y ~ x", family = "binomial",
              color = "blue", size = 0.5) + 
   ggtitle('Titanic disaster survival rate by age')

```

With facets we can view the relationship by categories. 

```{r lm.plot2}
# Create plot.
ggplot(titanic, aes(x = Age, y = Survived)) + geom_point() + 
  stat_smooth(formula = "y ~ x", method = "glm", 
              method.args = list(family = "binomial"), 
              color = "blue", size = 0.5) + 
  facet_wrap(~ Pclass) + 
  ggtitle('Titanic disaster survival rate by age and passenger class')
```

We can also add additional variables to plot by color or facet.

```{r lm.plot3}
ggplot(titanic, aes(x = Age, y = Survived, color = Sex)) + 
  geom_point(alpha = 0.3) + 
  stat_smooth(formula = "y ~ x", size = 0.5, 
              method = "glm", method.args = list(family = "binomial")) + 
  facet_grid(cols = vars(Pclass)) + 
  ggtitle('Titanic disaster survival rate by age, sex and passenger class')
```



# Session Information, Code, and Functions

The next three chunks should be included in the appendix of every R Markdown so 
that you document your session information, code, and functions defined in the 
document. This supports the reproducibility of your work.

```{r session.info}
#-----session information: beginning of Appendix -----------

# This promotes reproducibility by documenting the version of R and every package
# you used.
sessionInfo()

```

```{r appendix, ref.label=knitr::all_labels(), echo=TRUE, eval=FALSE, include=TRUE}
#-----appendix------------
```

```{r functions.defined.in.this.Rmd, eval = TRUE}
#-----functions defined in this Rmd ------------

# Show the names of all functions defined in the .Rmd
# (e.g. loaded in the environment)
lsf.str()

# Show the definitions of all functions loaded into the current environment  
lsf.str() %>% set_names() %>% map(get, .GlobalEnv)

```
